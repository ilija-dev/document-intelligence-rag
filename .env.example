# ── LLM Provider ──────────────────────────────────────────
# Option A: Ollama (local, free)
LLM_PROVIDER=ollama
LLM_BASE_URL=http://localhost:11434/v1
LLM_MODEL=llama3.2
LLM_API_KEY=ollama

# Option B: Groq (cloud, free tier)
# LLM_PROVIDER=groq
# LLM_BASE_URL=https://api.groq.com/openai/v1
# LLM_MODEL=llama-3.1-70b-versatile
# LLM_API_KEY=your-groq-api-key

# ── Redis ─────────────────────────────────────────────────
REDIS_URL=redis://localhost:6379
CACHE_TTL_SECONDS=3600

# ── ChromaDB ──────────────────────────────────────────────
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_COLLECTION=documents

# ── Ingestion Service ────────────────────────────────────
INGESTION_HOST=localhost
INGESTION_PORT=8100

# ── API Server ────────────────────────────────────────────
API_PORT=3000

# ── Persistence (SQLite fallback for CosmosDB) ───────────
DB_PROVIDER=sqlite
SQLITE_PATH=./data/conversations.db

# ── Embedding Model ──────────────────────────────────────
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ── Chunking Parameters ──────────────────────────────────
CHUNK_SIZE=500
CHUNK_OVERLAP=50
